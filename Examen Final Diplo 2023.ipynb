{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lbusatto/Examen-final/blob/main/Examen%20Final%20Diplo%202023.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0c636b70-2c89-4bb1-88c4-36fdb6d1e0e9",
      "metadata": {
        "id": "0c636b70-2c89-4bb1-88c4-36fdb6d1e0e9"
      },
      "source": [
        "<img src=\"https://uade.edu.ar/media/z3sesiag/uade_una_gran_universidad.png\" alt=\"drawing\" style=\"width:200px;\"/>\n",
        "\n",
        "# Examen Final Diplomatura en Ciencia de Datos 2023\n",
        "\n",
        "A continuación, se detallan las indicaciones generales para la resolución del examen. Tenga a bien leer todas las instrucciones y no dude en consultar si tiene alguna duda.\n",
        "\n",
        "1. El examen se realiza de forma grupal de acuerdo a la asignación previamente realizada (Grupo 1, Grupo 2, Grupo 3)\n",
        "\n",
        "2. La fecha de entrega de trabajo es el viernes 1 de Diciembre a las **19:00 hs** (Argentina)\n",
        "\n",
        "3. Tanto el código como el análisis y las visualizaciones se deben entregan en un notebook en formato `.ipynb.` Los datasets generados se deben entregar en formato comprimido o disponibilizarlos en un repositorio online (ej. Google Drive) y compartir el link. El nombre el notebook debe seguir la nomenclatura siguiente: \\\"Grupo#_Examen_Final_DiploDS.ipynb\\\"\n",
        "\n",
        "4. Puede utilizar diferentes herramientas para el desarrollo como `Jupyter`, `Colab`, `Spypder` o `VSCodium`, sin embargo, el trabajo final debe ser entregado en un notebook como estipulado en el punto 3. Este Notebook presenta un modelo de los puntos a utilizar. Puede usarse como template o elegir otro formato, pero se debe contar con los puntos indicados: carga de datos, EDA, división de los sets de datos, cross-validation, entrenamiento, evaluación y conclusiones\n",
        "\n",
        "5. Para visualizaciones durante el desarrollo del EDA se deben usar librerías matplotlib y seaborn, siendo las visualizaciones finales a exponer desarrolladas en Tableau, PowerBI u otra herramienta de BI\n",
        "\n",
        "6. La defensa del trabajo se realizará el **Lunes 4 de Diciembre de forma grupal y presencial**. Se les brindará un espacio de 25 a 30 minutos para la exposición y luego un espacio a preguntas. Se evaluará la claridad en la exposición, cohesión de la misma y la estructura completa. Deberán estar disponibles para responder preguntas sobre el código y el desarrollo del notebook además de la exposición.\n",
        "\n",
        "7. La nota se obtendrá en base a un promedio entre el desarrollo del trabajo, defensa del mismo en forma grupal y exposición individual\n",
        "\n",
        "Como parte del examen se evaluarán los siguientes conceptos:\n",
        "* Importar datos desde fuentes externas\n",
        "* Limpieza de datos\n",
        "* Gestión de datos y transformaciones\n",
        "* Modelado de datos\n",
        "* Visualizaciones\n",
        "* Selección de variables\n",
        "* Feature engineering\n",
        "* Manejo de sets de entranamiento y validación\n",
        "* Cross validation\n",
        "* Entrenamiento del modelo\n",
        "* Interpretación de resultados e indicadores\n",
        "* Almacenamiento de resultados"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8c847b9c-3636-4c26-8aee-6c164f3a4672",
      "metadata": {
        "id": "8c847b9c-3636-4c26-8aee-6c164f3a4672"
      },
      "source": [
        "## Consigna del Examen\n",
        "\n",
        "Como parte del equipo de datos de una EdTech se les requiere dar soporte a una conocida Universidad para entender por qué los alumnos tienen éxito o fracasan en su plan de carrera. Esta es una gran oportunidad para generar lazos con entidades y organizaciones de mayor importancia y despegar como startup. No está confirmado, pero hay un rumor de qué otras empresas estarán participando en busca de los mismos resultados.\n",
        "\n",
        "El objetivo presentado por la Universidad es poder predecir si un alumno/a se graduará, se mantendrá o abandonará la cursada. En palabras del CDAO\n",
        "\n",
        "*\"Hoy el mercado universitario es muy competitivo, incluso tenemos amenazas de otros sectores que nos 'canibalizan' parte del alumnado. Necesitamos actuar pronto para comprender los motivos y los perfiles que llevan a un/a alumno/a a continuar o abandonar para poder gestionar mejor las campañas y las acciones. Especialmente queremos enfocar en la retención, porque nos cuesta mucho dinero perder un/a alumno/a\"*\n",
        "\n",
        "Se solicita presentar en una sesión de 30 minutos el entendimiento del problema y los resultados obtenidos, así como recomendaciones de acción para la Universidad. La presentación debe estar orientada a un nivel de Director (conocimiento técnico pero interés comercial). La presentación debe contener soporte gráfico (visualizaciones o Dashboards de BI) que refuercen el mensaje.\n",
        "El equipo que estará presente en la exposición está compuesto por\n",
        "* Director de Arquitectura de Datos\n",
        "* Director de Analítica y Ciencia de Datos\n",
        "* Director de Marketing y Relaciones con Alumnos\n",
        "(es posible que el CDAO se sume en la sesión)\n",
        "\n",
        "El Director de Arquitectura de Datos requiere que se le presente un modelo de datos que pueda ser consumible luego desde su arquitectura analítica (la Universidad está construyendo un Datawarehouse) por lo cual requiere que al dataset principal se le sumen entidades de consulta (lookups) y que esto pueda ser consumible desde una herramienta de BI.\n",
        "* Hint: poder presentar un esquema de modelo relacional/estrella que permita comprender la relación entre, por ejemplo, el código 1 en la columna \"attendance\" se pueda visualizar como \"Daytime\"\n",
        "\n",
        "Los archivos a utilizar se encuentran almacenados en la siguiente URL:\n",
        "\n",
        "**Datasets**: `Academic Success and dropout.zip`"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "68707e26-658f-4fa7-9a52-19fc5f3375e3",
      "metadata": {
        "id": "68707e26-658f-4fa7-9a52-19fc5f3375e3"
      },
      "source": [
        "## Datos del Grupo (Ingrese los datos de los miembros del grupo)\n",
        "\n",
        "Nombre y Apellido | LU\n",
        "------------------|---\n",
        " |\n",
        " |\n",
        " |\n",
        " |\n",
        " |\n",
        " |\n",
        " |\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "962f4483-d2b3-4a5e-82df-b97ba4f023e7",
      "metadata": {
        "id": "962f4483-d2b3-4a5e-82df-b97ba4f023e7"
      },
      "source": [
        "## Importar Librerias"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "c15957f5-365e-4939-aeed-2403e3380c98",
      "metadata": {
        "tags": [],
        "id": "c15957f5-365e-4939-aeed-2403e3380c98"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import os\n",
        "from sklearn import preprocessing\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelBinarizer\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, classification_report\n",
        "# ..."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2a9c25dc-896a-4876-aabd-ed66331b76cb",
      "metadata": {
        "id": "2a9c25dc-896a-4876-aabd-ed66331b76cb"
      },
      "source": [
        "## Carga de datos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "11be0e9c-6fe1-43b8-836d-39f1b1b56c3e",
      "metadata": {
        "id": "11be0e9c-6fe1-43b8-836d-39f1b1b56c3e"
      },
      "outputs": [],
      "source": [
        "# Define el archivo CSV\n",
        "file_path = '/content/Examen/Academic Success and dropout.csv'\n",
        "\n",
        "# Lee el archivo CSV y usa la primera fila como encabezados\n",
        "df = pd.read_csv(file_path, sep=';', header=0, encoding='utf-8')\n",
        "\n",
        "# Ahora puedes imprimir el DataFrame\n",
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "764e65b7-f97c-4e38-894d-58d6725f36c8",
      "metadata": {
        "id": "764e65b7-f97c-4e38-894d-58d6725f36c8"
      },
      "outputs": [],
      "source": [
        "#Borra nulos habiendo corroborado que sólo generaban ruido\n",
        "df2 = df2.dropna()\n",
        "\n",
        "#Convierte Marital status a columnas binarias\n",
        "df2_encoded = pd.get_dummies(df2, columns=['Marital status'], prefix=['Marital status'])\n",
        "\n",
        "#df2_encoded = df.drop(columns='Marital status')\n",
        "\n",
        "\n",
        "# Almacenar 'Target' en 'y' y eliminarla antes de almacenarla en X\n",
        "y = df2_encoded['Target']\n",
        "df2_encoded = df2_encoded.drop(columns=['Target'])\n",
        "\n",
        "# Asignar 'df2_encoded' a 'X'\n",
        "X = df2_encoded\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0b2ea735-3a74-4e7f-9824-30e37ce7aa94",
      "metadata": {
        "id": "0b2ea735-3a74-4e7f-9824-30e37ce7aa94"
      },
      "outputs": [],
      "source": [
        "df2 = df.copy()  # Crear un nuevo DataFrame copiando los datos de df\n",
        "# Convertir todos los valores a cadenas (strings)\n",
        "df2['Target'] = df2['Target'].astype(str)\n",
        "# Filtrar las filas que no contienen 'Enrolled' en la columna 'Target'\n",
        "df2 = df2[~df2['Target'].str.contains('Enrolled')]\n",
        "df2"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### Normalizar valores (sin Marital status ni Target)\n",
        "# Excluyendo la primera y última columna\n",
        "columnas_a_normalizar = df.columns[1:-1] #Excluye Marital status y Target\n",
        "\n",
        "# Crear un objeto MinMaxScaler\n",
        "scaler = MinMaxScaler()\n",
        "\n",
        "# Normalizar las columnas seleccionadas y almacenar los resultados en df2\n",
        "df2[columnas_a_normalizar] = scaler.fit_transform(df[columnas_a_normalizar])"
      ],
      "metadata": {
        "id": "DEwhsw4k9-gA"
      },
      "id": "DEwhsw4k9-gA",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y.value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ubdqDs2G0Mob",
        "outputId": "a7bf7f13-bd13-4f45-bf57-d295bda350bb"
      },
      "id": "ubdqDs2G0Mob",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Graduate    2209\n",
              "Dropout     1421\n",
              "Name: Target, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 101
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# Divide tus datos en conjuntos de entrenamiento y prueba\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Crea un modelo de Árbol de Decisión multilabel\n",
        "decision_tree = DecisionTreeClassifier()\n",
        "\n",
        "# Entrena el modelo en el conjunto de entrenamiento\n",
        "decision_tree.fit(X_train, y_train)\n",
        "\n",
        "# Realiza predicciones en el conjunto de prueba\n",
        "y_pred_tree = decision_tree.predict(X_test)\n",
        "\n",
        "# Crea un modelo de Bosque Aleatorio multilabel\n",
        "random_forest = RandomForestClassifier(max_depth=14, n_estimators=110)\n",
        "\n",
        "\n",
        "# Entrena el modelo en el conjunto de entrenamiento\n",
        "random_forest.fit(X_train, y_train)\n",
        "\n",
        "# Realiza predicciones en el conjunto de prueba\n",
        "y_pred_forest = random_forest.predict(X_test)\n",
        "\n",
        "# Evalúa el rendimiento del Árbol de Decisión en los modos \"micro\", \"macro\" y \"weighted\"\n",
        "accuracy_micro_tree = accuracy_score(y_test, y_pred_tree)\n",
        "precision_micro_tree = precision_score(y_test, y_pred_tree, average='micro')\n",
        "recall_micro_tree = recall_score(y_test, y_pred_tree, average='micro')\n",
        "f1_micro_tree = f1_score(y_test, y_pred_tree, average='micro')\n",
        "\n",
        "precision_macro_tree = precision_score(y_test, y_pred_tree, average='macro')\n",
        "recall_macro_tree = recall_score(y_test, y_pred_tree, average='macro')\n",
        "f1_macro_tree = f1_score(y_test, y_pred_tree, average='macro')\n",
        "\n",
        "precision_weighted_tree = precision_score(y_test, y_pred_tree, average='weighted')\n",
        "recall_weighted_tree = recall_score(y_test, y_pred_tree, average='weighted')\n",
        "f1_weighted_tree = f1_score(y_test, y_pred_tree, average='weighted')\n",
        "\n",
        "# Evalúa el rendimiento del Bosque Aleatorio en los modos \"micro\", \"macro\" y \"weighted\"\n",
        "accuracy_micro_forest = accuracy_score(y_test, y_pred_forest)\n",
        "precision_micro_forest = precision_score(y_test, y_pred_forest, average='micro')\n",
        "recall_micro_forest = recall_score(y_test, y_pred_forest, average='micro')\n",
        "f1_micro_forest = f1_score(y_test, y_pred_forest, average='micro')\n",
        "\n",
        "precision_macro_forest = precision_score(y_test, y_pred_forest, average='macro')\n",
        "recall_macro_forest = recall_score(y_test, y_pred_forest, average='macro')\n",
        "f1_macro_forest = f1_score(y_test, y_pred_forest, average='macro')\n",
        "\n",
        "precision_weighted_forest = precision_score(y_test, y_pred_forest, average='weighted')\n",
        "recall_weighted_forest = recall_score(y_test, y_pred_forest, average='weighted')\n",
        "f1_weighted_forest = f1_score(y_test, y_pred_forest, average='weighted')\n",
        "\n",
        "# Imprime los resultados del Árbol de Decision\n",
        "print(\"Resultados del Árbol de Decision:\")\n",
        "print(\"Modo Micro:\")\n",
        "print(f\"Precision: {precision_micro_tree}\")\n",
        "print(f\"Recall: {recall_micro_tree}\")\n",
        "print(f\"F1-score: {f1_micro_tree}\")\n",
        "print(f\"Exactitud (Accuracy): {accuracy_micro_tree}\")\n",
        "\n",
        "print(\"\\nModo Macro:\")\n",
        "print(f\"Precision: {precision_macro_tree}\")\n",
        "print(f\"Recall: {recall_macro_tree}\")\n",
        "print(f\"F1-score: {f1_macro_tree}\")\n",
        "\n",
        "print(\"\\nModo Weighted:\")\n",
        "print(f\"Precision: {precision_weighted_tree}\")\n",
        "print(f\"Recall: {recall_weighted_tree}\")\n",
        "print(f\"F1-score: {f1_weighted_tree}\")\n",
        "\n",
        "# Imprime los resultados del Bosque Aleatorio\n",
        "print(\"\\nResultados del Bosque Aleatorio:\")\n",
        "print(\"Modo Micro:\")\n",
        "print(f\"Precision: {precision_micro_forest}\")\n",
        "print(f\"Recall: {recall_micro_forest}\")\n",
        "print(f\"F1-score: {f1_micro_forest}\")\n",
        "print(f\"Exactitud (Accuracy): {accuracy_micro_forest}\")\n",
        "\n",
        "print(\"\\nModo Macro:\")\n",
        "print(f\"Precision: {precision_macro_forest}\")\n",
        "print(f\"Recall: {recall_macro_forest}\")\n",
        "print(f\"F1-score: {f1_macro_forest}\")\n",
        "\n",
        "print(\"\\nModo Weighted:\")\n",
        "print(f\"Precision: {precision_weighted_forest}\")\n",
        "print(f\"Recall: {recall_weighted_forest}\")\n",
        "print(f\"F1-score: {f1_weighted_forest}\")\n"
      ],
      "metadata": {
        "id": "5hlI5Ep7UXAp",
        "outputId": "d8d5d5b4-5620-422e-f553-e0c5fcae64fa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "5hlI5Ep7UXAp",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Resultados del Árbol de Decisión:\n",
            "Modo Micro:\n",
            "Precisión: 0.8549127640036731\n",
            "Recall: 0.8549127640036731\n",
            "F1-score: 0.8549127640036731\n",
            "Exactitud (Accuracy): 0.8549127640036731\n",
            "\n",
            "Modo Macro:\n",
            "Precisión: 0.8451819514371295\n",
            "Recall: 0.8488727858293076\n",
            "F1-score: 0.8469090326713644\n",
            "\n",
            "Modo Weighted:\n",
            "Precisión: 0.8558981627445889\n",
            "Recall: 0.8549127640036731\n",
            "F1-score: 0.8552984859955914\n",
            "\n",
            "Resultados del Bosque Aleatorio:\n",
            "Modo Micro:\n",
            "Precisión: 0.9090909090909091\n",
            "Recall: 0.9090909090909091\n",
            "F1-score: 0.9090909090909091\n",
            "Exactitud (Accuracy): 0.9090909090909091\n",
            "\n",
            "Modo Macro:\n",
            "Precisión: 0.9134146341463415\n",
            "Recall: 0.8930434782608696\n",
            "F1-score: 0.9012977382276603\n",
            "\n",
            "Modo Weighted:\n",
            "Precisión: 0.91019955654102\n",
            "Recall: 0.9090909090909091\n",
            "F1-score: 0.9079448545521961\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "### CONVERTIR TARGET EN BINARIO\n",
        "# Aplica el LabelEncoder a la columna 'Target', previamente guardada en y\n",
        "label_encoder = LabelEncoder()\n",
        "y_numeric = label_encoder.fit_transform(y)\n",
        "y = y_numeric"
      ],
      "metadata": {
        "id": "YK705rvmR9Jw"
      },
      "id": "YK705rvmR9Jw",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Divide los datos en conjuntos de entrenamiento y prueba\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Define una cuadricula de hiperparametros que deseas ajustar\n",
        "param_grid = {\n",
        "    'n_estimators': [90, 100, 110],\n",
        "    'max_depth': [14],\n",
        "    # Agrega mas hiperparametros segun sea necesario\n",
        "}\n",
        "\n",
        "# Crea una instancia del Random Forest Classifier ponderado\n",
        "rf_model = RandomForestClassifier()\n",
        "\n",
        "# Crea un objeto GridSearchCV\n",
        "grid_search = GridSearchCV(rf_model, param_grid, cv=5, scoring='accuracy')\n",
        "\n",
        "# Realiza el grid search en los datos de entrenamiento\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "# Obtiene los mejores hiperparametros encontrados\n",
        "mejores_hiperparametros = grid_search.best_params_\n",
        "\n",
        "# Evalúa el modelo con los mejores hiperparametros en los datos de prueba\n",
        "modelo_optimizado = grid_search.best_estimator_\n",
        "precision = modelo_optimizado.score(X_test, y_test)\n",
        "\n",
        "print(\"Mejores hiperparametros:\", mejores_hiperparametros)\n",
        "print(\"Precisión en datos de prueba:\", precision)\n"
      ],
      "metadata": {
        "id": "T1g2HA2fVixp"
      },
      "id": "T1g2HA2fVixp",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Dividir los datos en conjuntos de entrenamiento y prueba\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Crear un modelo de regresion logística\n",
        "model = LogisticRegression()\n",
        "model = LogisticRegression(solver='saga')\n",
        "# Entrenar el modelo con los datos de entrenamiento\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Realizar predicciones en los datos de prueba\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Calcular la precision del modelo\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "print(\"Precision del modelo:\", accuracy)\n"
      ],
      "metadata": {
        "id": "cKUiE6cLRyev",
        "outputId": "c6c4123d-eca5-4ad4-9b0d-7dbeea741bfb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "cKUiE6cLRyev",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Precisión del modelo: 0.6831955922865014\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e9660757-115c-450a-9052-d95203d76488",
      "metadata": {
        "tags": [],
        "id": "e9660757-115c-450a-9052-d95203d76488"
      },
      "outputs": [],
      "source": [
        "param_archivos = [\n",
        "    {'archivos': ['/content/Examen/nation.csv'], 'sep': '-'},\n",
        "    {'archivos': ['/content/Examen/education.csv', '/content/Examen/father educ.csv'], 'sep': '\\t'},\n",
        "    {'archivos': ['/content/Examen/course.csv',\n",
        "                  '/content/Examen/mother educ.csv',\n",
        "                  '/content/Examen/father educ.csv',\n",
        "                  '/content/Examen/marital.csv',\n",
        "                  '/content/Examen/marital.csv'], 'sep': ';'},\n",
        "    {'archivos': ['/content/Examen/application.csv'], 'sep': ','}\n",
        "]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "21e9af32-16f1-4e47-92fa-a0488ed710d4",
      "metadata": {
        "id": "21e9af32-16f1-4e47-92fa-a0488ed710d4"
      },
      "source": [
        "## Preparación y análisis de datos (EDA)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b4423da5-39b1-43b5-b28d-fb659a014e17",
      "metadata": {
        "id": "b4423da5-39b1-43b5-b28d-fb659a014e17",
        "outputId": "f8c474bf-9f7f-439c-8aed-1e80e0fc60f0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 2, 0, ..., 0, 2, 2])"
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1b90af79-42b8-4de9-a3bd-a917fce3d0a6",
      "metadata": {
        "id": "1b90af79-42b8-4de9-a3bd-a917fce3d0a6"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ae7a635a-687d-4e16-8a3a-d706d783ca89",
      "metadata": {
        "id": "ae7a635a-687d-4e16-8a3a-d706d783ca89"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "b59b8f7a-66ea-4bfb-a95f-5c50d91d295d",
      "metadata": {
        "tags": [],
        "id": "b59b8f7a-66ea-4bfb-a95f-5c50d91d295d"
      },
      "source": [
        "## Data split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "21540ace-cb24-418d-9b31-22012307e15e",
      "metadata": {
        "id": "21540ace-cb24-418d-9b31-22012307e15e"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9c53a61b-4c45-4b18-a838-4907217153ac",
      "metadata": {
        "id": "9c53a61b-4c45-4b18-a838-4907217153ac"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d09b055a-72f9-4763-bc78-0f0573f474d3",
      "metadata": {
        "id": "d09b055a-72f9-4763-bc78-0f0573f474d3"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "6595d1de-25f4-46a7-bae6-fdb8c81aeb31",
      "metadata": {
        "id": "6595d1de-25f4-46a7-bae6-fdb8c81aeb31"
      },
      "source": [
        "## Selección de atributos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f2bca906-d53b-4ef0-be51-ce6d75eba78e",
      "metadata": {
        "id": "f2bca906-d53b-4ef0-be51-ce6d75eba78e"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4c407d8d-098a-4c31-a1a0-084a32eb4a12",
      "metadata": {
        "id": "4c407d8d-098a-4c31-a1a0-084a32eb4a12"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c4dd6971-07a0-41c4-8f53-5a880e9204a4",
      "metadata": {
        "id": "c4dd6971-07a0-41c4-8f53-5a880e9204a4"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "a53ee563-2057-4743-b046-bdeeeffbc68b",
      "metadata": {
        "id": "a53ee563-2057-4743-b046-bdeeeffbc68b"
      },
      "source": [
        "## Estandarización"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c807ab0e-bb52-4224-b177-63c5e850f947",
      "metadata": {
        "id": "c807ab0e-bb52-4224-b177-63c5e850f947"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ceca78a6-9e1c-4a3f-a1a5-e5fef75bfb56",
      "metadata": {
        "id": "ceca78a6-9e1c-4a3f-a1a5-e5fef75bfb56"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "17b6e9fb-e3a6-4f1e-bd58-443ab90de03f",
      "metadata": {
        "id": "17b6e9fb-e3a6-4f1e-bd58-443ab90de03f"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "c03a8a38-03ef-443a-86c8-1a6635a91ce8",
      "metadata": {
        "tags": [],
        "id": "c03a8a38-03ef-443a-86c8-1a6635a91ce8"
      },
      "source": [
        "## Cross-Validation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a33cb93b-24ba-46d6-8aa7-e80cde893344",
      "metadata": {
        "id": "a33cb93b-24ba-46d6-8aa7-e80cde893344"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ad779dff-e655-47d2-bac1-2006b2586d44",
      "metadata": {
        "id": "ad779dff-e655-47d2-bac1-2006b2586d44"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e36dc299-a991-4ed1-9a1f-17f51cbf279c",
      "metadata": {
        "id": "e36dc299-a991-4ed1-9a1f-17f51cbf279c"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "2139337b-6068-470c-a74d-c209345e061d",
      "metadata": {
        "tags": [],
        "id": "2139337b-6068-470c-a74d-c209345e061d"
      },
      "source": [
        "## Entrenamiento modelo definitivo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "adf80e20-dd02-4ee9-ba7f-40255d35a537",
      "metadata": {
        "id": "adf80e20-dd02-4ee9-ba7f-40255d35a537"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6be2feed-529a-4cf0-80df-cfef1858d490",
      "metadata": {
        "id": "6be2feed-529a-4cf0-80df-cfef1858d490"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "14a080d2-708d-4258-81bb-72cf51801476",
      "metadata": {
        "id": "14a080d2-708d-4258-81bb-72cf51801476"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "ed5e561e-974e-4d5a-a054-19e71122d1e4",
      "metadata": {
        "tags": [],
        "id": "ed5e561e-974e-4d5a-a054-19e71122d1e4"
      },
      "source": [
        "## Evaluación modelo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cc231f73-0b62-42ac-b326-6c09369ec887",
      "metadata": {
        "id": "cc231f73-0b62-42ac-b326-6c09369ec887"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "16023b0d-fa11-457c-b803-aada6d6516cd",
      "metadata": {
        "id": "16023b0d-fa11-457c-b803-aada6d6516cd"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e200aa09-3ff9-494f-9ebc-bc55afc0d898",
      "metadata": {
        "id": "e200aa09-3ff9-494f-9ebc-bc55afc0d898"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "51cf63b6-2fc7-4f40-ba10-acb6b4e6352d",
      "metadata": {
        "id": "51cf63b6-2fc7-4f40-ba10-acb6b4e6352d"
      },
      "source": [
        "## Conclusiones"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4c5c0f35-7a89-495e-a889-5c018b6666b1",
      "metadata": {
        "id": "4c5c0f35-7a89-495e-a889-5c018b6666b1"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c07b46a0-fc2a-44d6-b2e5-80e0b9f49722",
      "metadata": {
        "id": "c07b46a0-fc2a-44d6-b2e5-80e0b9f49722"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.1"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}